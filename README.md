ğŸ–ï¸ AirBuddy â€“ Control Your PC with Gestures & Voice
AirBuddy is a smart, touchless control system that lets you interact with your computer using hand gestures and voice commands. Designed for accessibility, convenience, and modern interaction, it combines computer vision and speech recognition to replace traditional input methods.

ğŸš€ Key Features
ğŸ–ï¸ Real-time Hand Gesture Recognition
Scroll, click, zoom, switch apps, and control volume using simple hand movements.

ğŸ—£ï¸ Voice Command Support
Execute actions like â€œscroll downâ€ or â€œopen browserâ€ through natural voice input.

ğŸ›ï¸ Intuitive Settings GUI
Adjust sensitivity, scroll speed, delay time, and gesture mapping without touching the code.

ğŸ§  Dynamic Gesture Training Mode
Add, edit, and delete gestures via the interface and map them to any action on the fly.

ğŸ‘ Multi-Hand Support
Recognize and respond to gestures from both hands for more complex interactions.

ğŸ”Š Sound Feedback
Audio cues confirm each gesture or voice action for better user experience.

ğŸ› ï¸ Built With
Python

OpenCV & MediaPipe

PyAutoGUI

SpeechRecognition

Tkinter

Pygame

âš™ï¸ Getting Started
Clone the repo
git clone https://github.com/yourusername/AirBuddy.git

Install dependencies
pip install -r requirements.txt

Run the application
python Hand.py

ğŸ’¡ Use Cases
Hands-free PC control during presentations

Accessibility tool for users with limited mobility

Touchless navigation in hygiene-sensitive environments

Personal productivity or AI project showcase
